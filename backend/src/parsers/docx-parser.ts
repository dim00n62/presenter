// backend/src/parsers/docx-parser.ts

import mammoth from 'mammoth';
import { readFile } from 'fs/promises';
import { semanticChunker, SemanticChunk } from '../services/semantic-chunker.js';

interface DocxParseResult {
    type: 'docx';
    sections: Array<{
        title?: string;
        content: string;
        level: number;
    }>;
    fullText: string;
    metadata: {
        paragraphs: number;
        hasImages: boolean;
    };
}

export class DocxParser {
    async parse(filepath: string): Promise<DocxParseResult> {
        try {
            console.log('üìù Parsing DOCX:', filepath);

            const buffer = await readFile(filepath);

            // Extract text with basic structure
            const result = await mammoth.extractRawText({ buffer });
            const fullText = result.value;

            // Also extract with structure (headings)
            const htmlResult = await mammoth.convertToHtml({ buffer });
            const hasImages = htmlResult.value.includes('<img');

            console.log(`üìä DOCX extracted: ${fullText.length} characters`);

            // Split into sections based on structure
            const sections = this.parseSections(fullText);

            console.log(`‚úÖ DOCX parsed: ${sections.length} sections found`);

            return {
                type: 'docx',
                sections,
                fullText,
                metadata: {
                    paragraphs: sections.length,
                    hasImages
                }
            };

        } catch (error) {
            console.error('DOCX parsing error:', error);
            throw new Error(`Failed to parse DOCX: ${error}`);
        }
    }

    private parseSections(text: string): Array<{ title?: string; content: string; level: number }> {
        const lines = text.split('\n').filter(line => line.trim());
        const sections: Array<{ title?: string; content: string; level: number }> = [];

        let currentSection: { title?: string; content: string; level: number } | null = null;

        for (const line of lines) {
            const trimmed = line.trim();

            if (!trimmed) continue;

            // Detect headings (simple heuristic: short lines that might be titles)
            const isLikelyHeading = trimmed.length < 100 &&
                !trimmed.endsWith('.') &&
                !trimmed.endsWith(',') &&
                /^[–ê-–ØA-Z0-9]/.test(trimmed);

            if (isLikelyHeading && (!currentSection || currentSection.content.length > 0)) {
                // Start new section
                if (currentSection) {
                    sections.push(currentSection);
                }

                currentSection = {
                    title: trimmed,
                    content: '',
                    level: 1
                };
            } else if (currentSection) {
                // Add to current section
                currentSection.content += (currentSection.content ? '\n' : '') + trimmed;
            } else {
                // First content without heading
                currentSection = {
                    content: trimmed,
                    level: 0
                };
            }
        }

        // Add last section
        if (currentSection) {
            sections.push(currentSection);
        }

        return sections.length > 0 ? sections : [{
            content: text,
            level: 0
        }];
    }

    /**
     * üÜï SEMANTIC CHUNKING - —É–º–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
     */
    createTextChunks(result: DocxParseResult): Array<{ content: string; metadata: any }> {
        console.log('üìö [DOCX Parser] Creating semantic chunks...');

        // –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –¥–ª—è semantic chunking
        const fullText = result.fullText;

        if (!fullText || fullText.trim().length === 0) {
            console.warn('‚ö†Ô∏è Empty DOCX document');
            return [];
        }

        // Semantic chunking
        const semanticChunks = semanticChunker.chunk(fullText, {
            strategy: 'hybrid',
            maxChunkSize: 1500,
            minChunkSize: 300,
            overlapSize: 200,
            preserveSentences: true,
        });

        // –û–±–æ–≥–∞—â–∞–µ–º metadata –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–µ–∫—Ü–∏—è—Ö
        const chunks = semanticChunks.map((chunk: SemanticChunk) => {
            // –ù–∞—Ö–æ–¥–∏–º –∫ –∫–∞–∫–æ–π —Å–µ–∫—Ü–∏–∏ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è chunk
            const section = this.findSectionForChunk(chunk, result.sections);

            return {
                content: chunk.content,
                metadata: {
                    type: 'semantic_chunk',
                    chunkIndex: chunk.metadata.chunkIndex,
                    wordCount: chunk.metadata.wordCount,
                    sentences: chunk.metadata.sentences,
                    topics: chunk.metadata.topics,
                    chunkingStrategy: chunk.metadata.type,
                    // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                    sectionTitle: section?.title,
                    sectionLevel: section?.level,
                }
            };
        });

        console.log(`‚úÖ [DOCX Parser] Created ${chunks.length} semantic chunks (avg ${Math.round(chunks.reduce((sum, c) => sum + c.metadata.wordCount, 0) / chunks.length)} words)`);

        return chunks;
    }

    /**
     * üîß LEGACY: –°—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ (–ø–æ —Å–µ–∫—Ü–∏—è–º) - –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
     */
    createSectionBasedChunks(result: DocxParseResult): Array<{ content: string; metadata: any }> {
        console.log('üìÑ [DOCX Parser] Creating section-based chunks (legacy mode)...');

        const chunks: Array<{ content: string; metadata: any }> = [];

        result.sections.forEach((section, index) => {
            const content = section.title
                ? `${section.title}\n\n${section.content}`
                : section.content;

            if (content.trim()) {
                chunks.push({
                    content: content.trim(),
                    metadata: {
                        type: 'section',
                        sectionIndex: index,
                        title: section.title,
                        level: section.level,
                        wordCount: content.split(/\s+/).length
                    }
                });
            }
        });

        return chunks;
    }

    private findSectionForChunk(
        chunk: SemanticChunk,
        sections: Array<{ title?: string; content: string; level: number }>
    ): { title?: string; level: number } | null {
        // –ò—â–µ–º —Å–µ–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∞—á–∞–ª–æ chunk
        const chunkStart = chunk.content.slice(0, 100);

        for (const section of sections) {
            const sectionText = section.title
                ? `${section.title}\n\n${section.content}`
                : section.content;

            if (sectionText.includes(chunkStart)) {
                return {
                    title: section.title,
                    level: section.level,
                };
            }
        }

        return null;
    }
}

export const docxParser = new DocxParser();
